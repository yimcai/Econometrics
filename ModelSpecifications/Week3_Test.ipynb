{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @hidecode\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices, dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"test3.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Use general-to-specific to come to a model. Start by regressing the federal funds rate on the other 7 variables and eliminate 1 variable at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X1 = dmatrices(\"INTRATE ~ INFL + PROD + UNEMPL + COMMPRI + PCE + PERSINC +HOUST \", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_mod = sm.OLS(y, X1).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Ordinary Least Square to fit the model gives the result as follows. (estimated by statsmodels with Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                INTRATE   R-squared:                       0.639\n",
      "Model:                            OLS   Adj. R-squared:                  0.635\n",
      "Method:                 Least Squares   F-statistic:                     164.5\n",
      "Date:                Sun, 06 May 2018   Prob (F-statistic):          1.64e-139\n",
      "Time:                        17:31:02   Log-Likelihood:                -1449.2\n",
      "No. Observations:                 660   AIC:                             2914.\n",
      "Df Residuals:                     652   BIC:                             2950.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2212      0.245     -0.903      0.367      -0.702       0.260\n",
      "INFL           0.6961      0.062     11.185      0.000       0.574       0.818\n",
      "PROD          -0.0577      0.040     -1.447      0.148      -0.136       0.021\n",
      "UNEMPL         0.1025      0.097      1.059      0.290      -0.088       0.292\n",
      "COMMPRI       -0.0055      0.003     -1.857      0.064      -0.011       0.000\n",
      "PCE            0.3444      0.069      4.958      0.000       0.208       0.481\n",
      "PERSINC        0.2470      0.061      4.077      0.000       0.128       0.366\n",
      "HOUST         -0.0194      0.005     -4.155      0.000      -0.029      -0.010\n",
      "==============================================================================\n",
      "Omnibus:                       28.142   Durbin-Watson:                   0.101\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.034\n",
      "Skew:                           0.365   Prob(JB):                     1.23e-09\n",
      "Kurtosis:                       3.980   Cond. No.                         102.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print (complete_mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following the \"general-to-specific\" rule, the variable (except the constant term) with the largest p-value will be eliminated from the model when it is not significant. For example, the variable $UNEMPL$ will be excluded from the model first. \n",
    "\n",
    "After iterating this process, the variables being eliminated are $UNEMPL, PROD$ sequentially, and the final result is given as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                INTRATE   R-squared:                       0.637\n",
      "Model:                            OLS   Adj. R-squared:                  0.635\n",
      "Method:                 Least Squares   F-statistic:                     229.9\n",
      "Date:                Sun, 06 May 2018   Prob (F-statistic):          2.03e-141\n",
      "Time:                        17:31:02   Log-Likelihood:                -1450.2\n",
      "No. Observations:                 660   AIC:                             2912.\n",
      "Df Residuals:                     654   BIC:                             2939.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2401      0.230     -1.042      0.298      -0.692       0.212\n",
      "INFL           0.7175      0.057     12.555      0.000       0.605       0.830\n",
      "COMMPRI       -0.0075      0.003     -2.841      0.005      -0.013      -0.002\n",
      "PCE            0.3405      0.059      5.756      0.000       0.224       0.457\n",
      "PERSINC        0.2402      0.059      4.048      0.000       0.124       0.357\n",
      "HOUST         -0.0205      0.004     -4.678      0.000      -0.029      -0.012\n",
      "==============================================================================\n",
      "Omnibus:                       23.848   Durbin-Watson:                   0.100\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.255\n",
      "Skew:                           0.354   Prob(JB):                     1.63e-07\n",
      "Kurtosis:                       3.797   Cond. No.                         94.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X2 = dmatrices(\"INTRATE ~ INFL + COMMPRI + PCE + PERSINC +HOUST \", df)\n",
    "partial_mod = sm.OLS(y, X2).fit()\n",
    "print (partial_mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Use specific-to-general to come to a model. Start by regressing the federal funds rate on only a constant and add 1 variable at a time. Is the model the same as in (a)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "following the \"specific-to_general\", variables including $INFL, PROD, UNEMPL, COMMPRI, PCE, PERSINC, HOUST$ will be added to the model sequentilly and only variables with significance will be kept. As can be seen from the result, it is the same as in **(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                INTRATE   R-squared:                       0.637\n",
      "Model:                            OLS   Adj. R-squared:                  0.635\n",
      "Method:                 Least Squares   F-statistic:                     229.9\n",
      "Date:                Sun, 06 May 2018   Prob (F-statistic):          2.03e-141\n",
      "Time:                        17:31:02   Log-Likelihood:                -1450.2\n",
      "No. Observations:                 660   AIC:                             2912.\n",
      "Df Residuals:                     654   BIC:                             2939.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2401      0.230     -1.042      0.298      -0.692       0.212\n",
      "INFL           0.7175      0.057     12.555      0.000       0.605       0.830\n",
      "COMMPRI       -0.0075      0.003     -2.841      0.005      -0.013      -0.002\n",
      "PCE            0.3405      0.059      5.756      0.000       0.224       0.457\n",
      "PERSINC        0.2402      0.059      4.048      0.000       0.124       0.357\n",
      "HOUST         -0.0205      0.004     -4.678      0.000      -0.029      -0.012\n",
      "==============================================================================\n",
      "Omnibus:                       23.848   Durbin-Watson:                   0.100\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.255\n",
      "Skew:                           0.354   Prob(JB):                     1.63e-07\n",
      "Kurtosis:                       3.797   Cond. No.                         94.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X3 = dmatrices(\"INTRATE ~ INFL + COMMPRI + PCE + PERSINC + HOUST\", df)\n",
    "specific_mod = sm.OLS(y, X3).fit()\n",
    "print (specific_mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Compare your model from (a) and the Taylor rule of equation (1). Consider R2, AIC and BIC. Which of the models do you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As given by equation (1), the model goes as: \n",
    "\n",
    "> $INTRATE = constant + INFL + PROD + \\varepsilon$\n",
    "\n",
    "and the model result is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                INTRATE   R-squared:                       0.575\n",
      "Model:                            OLS   Adj. R-squared:                  0.573\n",
      "Method:                 Least Squares   F-statistic:                     443.9\n",
      "Date:                Sun, 06 May 2018   Prob (F-statistic):          1.06e-122\n",
      "Time:                        17:31:02   Log-Likelihood:                -1502.8\n",
      "No. Observations:                 660   AIC:                             3012.\n",
      "Df Residuals:                     657   BIC:                             3025.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2489      0.176      7.088      0.000       0.903       1.595\n",
      "INFL           0.9750      0.033     29.785      0.000       0.911       1.039\n",
      "PROD           0.0947      0.020      4.805      0.000       0.056       0.133\n",
      "==============================================================================\n",
      "Omnibus:                       12.297   Durbin-Watson:                   0.065\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               12.444\n",
      "Skew:                           0.326   Prob(JB):                      0.00199\n",
      "Kurtosis:                       3.168   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y, X3 = dmatrices(\"INTRATE ~ INFL + PROD \", df)\n",
    "taylor_mod = sm.OLS(y, X3).fit()\n",
    "print (taylor_mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison betwen model(a) and Taylor rule (eq.1) is listed below. Clearly, model (a) has higher $R^{2}$ and lower AIC and BIC. Therefore, I perfer model(a) to Taylor rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| MODEL  | $R^{2}$  | AIC  | BIC  |   \n",
    "|---|---|---|---|---|\n",
    "| model (a) |  0.637 | 2912  | 2939  |   \n",
    "| Taylor rule  | 0.575  | 3012  | 3025  |   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Test the Taylor rule of equation (1) using the RESET test, Chow break and forecast test (with in both tests as break date January 1980) and a Jarque-Bera test. What do you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) RESET test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the $\\tilde y$ is calculated using the restricted model (i.e., correct specification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reset = df.copy()\n",
    "#use the predicted y\n",
    "df_reset[\"y_predict2\"] = np.square(taylor_mod.predict(X3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the unrestricted model is fitted by adding another term $\\tilde y^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X4 = dmatrices(\"INTRATE ~ INFL + PROD + y_predict2\" , df_reset)\n",
    "reset_mod = sm.OLS(y, X4).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistis is $T_{RESET} =  \\frac{(e_{0}^{'}e_{0}- e_{1}^{'}e_{1})/p}{e_{1}^{'}e_{1}/(n-p-k)}, p =1,n = 660, k = 3$,  $T \\sim F(1, 656)$\n",
    "\n",
    "Also, $e_{0}$ is the residuals of the restricted model while $e_{1}$ is the residuals of the unrestricted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{RESET}$ is calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5371195394336974"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e0, e1 = taylor_mod.resid, reset_mod.resid\n",
    "T_reset = (np.dot(e0.T, e0) - np.dot(e1.T, e1))/( np.dot(e1.T, e1) / (660-3-1))\n",
    "T_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the calculator here http://stattrek.com/online-calculator/f-distribution.aspx gives p-value __0.11__ thus failing to rejects the null hypothesis (correct specification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Chow break test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: x**2 if x > 2 else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df[df.apply(lambda x: True if np.int(x[\"OBS\"].split(\":\")[0]) < 1980 else False, axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df[~df.OBS.isin(df1.OBS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y5,X5 = dmatrices(\"INTRATE ~ INFL + PROD\", df1)\n",
    "y6,X6 = dmatrices(\"INTRATE ~ INFL + PROD\", df2)\n",
    "chow1_mod = sm.OLS(y5, X5).fit()\n",
    "chow2_mod = sm.OLS(y6, X6).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistic is calculated as : $T_{ChowTest} = \\frac {(S_{0} - S_{1}- S_{2})/k} {(S_{1} +S_{2})/(n-2k)}$ and $T_{ChowTest}$ is calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_R = taylor_mod.resid\n",
    "e_1 = chow1_mod.resid\n",
    "e_2 = chow2_mod.resid\n",
    "S_1 = np.dot(e_1.T, e_1)\n",
    "S_2 = np.dot(e_2.T, e_2)\n",
    "S_0 = np.dot(e_R.T, e_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.735013728565036"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((S_0 - S_1 -S_2) / 3) / ((S_1 + S_2) / (660 -6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, using the calculator here http://stattrek.com/online-calculator/f-distribution.aspx gives p-value 0.000 thus rejecting the null hypothesis. Therefore, there is a break before and after Jan,1980 based on Chow break test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Chow forecast test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lecture 3.4, $e_{2} =0,   F = \\frac {(S_{0} - S_{1})/n_{2}} {S_{1}/(n_{1}-k)},  F \\sim F(n_{2}, n_{1} -k)$, where $n_{1} = 240, n_{2}= 420, k = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{ChowForcast}$ is calculated as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5105180043224093"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((S_0 - S_1)/420)/(S_1/(240 -3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the p-value is 0.000 and thus rejecting the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Jarque-Bera test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JB statistic is calculated as  12.444, whose corresponding p-value is 0.00199. Therefore the normality of the redisuals is rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the model should not consider including non-linear terms (at least quadratic ones) but I recommend using two models, one for data before Jan,1980 and the other for data after jan, 1980 given the results of Chow Break and Chow Forecast test. However, the result of JB test does raise a little bit concern over the assumption that residuals is distributed normall. Thus, further refinements might be needed to address this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
